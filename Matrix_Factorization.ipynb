{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Matrix_Factorization.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ayushbond007/BOOK-recommender-system/blob/main/Matrix_Factorization.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y4OgjI58bbIY"
      },
      "source": [
        "\n",
        "\n",
        "# basics\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# visualization\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "# tools\n",
        "import scipy\n",
        "import math\n",
        "import random\n",
        "import sklearn\n",
        "import string\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pkQulE0YpNx_",
        "outputId": "5c506600-a8fe-439a-9f24-9b15ecbb30d7"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pPPq5TIypcd6"
      },
      "source": [
        "finalbooks=pd.read_csv(\"/content/drive/MyDrive/BOOK RECOMENDATION /finalfor modelling.csv\")\n",
        "ratings=pd.read_csv(\"/content/drive/MyDrive/BOOK RECOMENDATION /new_rating.csv\")\n",
        "test=pd.read_csv(\"/content/drive/MyDrive/BOOK RECOMENDATION /test.csv\")\n",
        "train=pd.read_csv(\"/content/drive/MyDrive/BOOK RECOMENDATION /train.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CwpXuKMRbxB9"
      },
      "source": [
        "\n",
        "\n",
        "def dcg_k(r, k):\n",
        "\n",
        "    r = np.asfarray(r)[:k]\n",
        "    return np.sum(2**r / np.log2(np.arange(2, r.size + 2)))      \n",
        "\n",
        "\n",
        "\n",
        "def ndcg_k(r, k):\n",
        "\n",
        "    dcg_max = dcg_k(sorted(r, reverse=True), k)\n",
        "    if not dcg_max:\n",
        "        return 0.\n",
        "    return dcg_k(r, k) / dcg_max\n",
        "\n",
        "def mean_ndcg(rs):\n",
        "\n",
        "    return np.mean([ndcg_k(r, len(r)) for r in rs])\n",
        "\n",
        "def rmse(y,h):\n",
        "\n",
        "    a = y-h\n",
        "\n",
        "    return np.sqrt(sum(a**2)/len(a))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LlXyHh_rc8Lh"
      },
      "source": [
        "# MATRIX FACTORIZATION\n",
        "def new_R(data, U, B):\n",
        "    nR = np.zeros(data.shape[0])\n",
        "    c = 0\n",
        "    for i in range(data.shape[0]):\n",
        "        #if i % 10000000 == 0:\n",
        "            #print('step ' + str(i))\n",
        "        nR[c] = B[:, data.newbookid[i] - 1] @ U[data.newuser_id[i] - 1, :]\n",
        "\n",
        "        c += 1\n",
        "    return nR\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r5OdsMKFc8Vi"
      },
      "source": [
        "## Alternate Least Square\n",
        "\n",
        "def ALS(train, k, lamu = 0.1, lamb = 0.1):\n",
        "    users = np.unique(train.newuser_id)\n",
        "    books = np.unique(train.newbookid)\n",
        "    nu = len(users)\n",
        "    nb = len(books)\n",
        "\n",
        "# Initialize U and B\n",
        "\n",
        "    #U = np.random.rand(max(users), k)/50\n",
        "    #B = np.random.rand(k, max(books))/50\n",
        "    #B[0, books - 1] = finalbooks.average_rating[books - 1]\n",
        "\n",
        "    U = np.ones((max(users), k)) / np.sqrt(k)\n",
        "    B = np.ones((k, max(books))) / np.sqrt(k)\n",
        "    #B[0, books - 1] = finalbooks.average_rating[books - 1]\n",
        "    \n",
        "    iter = 1\n",
        "    RMSE = 3\n",
        "    dRMSE = 1\n",
        "    rms = []\n",
        "    stop = 0.0001\n",
        "    max_iter = 24\n",
        "    \n",
        "    while (dRMSE > stop) and (iter < max_iter):\n",
        "      for i in users:\n",
        "        ind_B = train.newbookid[train.newuser_id == i] - 1\n",
        "        sub_B = B[:, ind_B]\n",
        "        nui = sub_B.shape[1]\n",
        "        Ai = sub_B @ np.transpose(sub_B) + lamu * np.identity(k)  #*nui\n",
        "        Vi = sub_B @ train.rating[train.newuser_id == i]\n",
        "        U[i - 1, :] = np.linalg.pinv(Ai) @ Vi\n",
        "        #if i % 1000 == 0: print('user ' + str(i))\n",
        "      nR = new_R(train, U, B)\n",
        "      new_RMSE = rmse(nR,train.rating)\n",
        "      dRMSEu = (RMSE - new_RMSE)\n",
        "      RMSE = new_RMSE.copy()\n",
        "      #print('dRMSE = ' + str(dRMSE))\n",
        "      rms.append(RMSE)\n",
        "      iter += 1\n",
        "      print(\"step: \", iter)\n",
        "\n",
        "      for i in books:\n",
        "        ind_U = train.newuser_id[train.newbookid == i] - 1\n",
        "        sub_U = U[ind_U, :]\n",
        "        nbi = sub_U.shape[0]\n",
        "        Ai = np.transpose(sub_U) @ sub_U + lamb * np.identity(k)   #*nbi\n",
        "        Vi = np.transpose(sub_U) @ train.rating[train.newbookid == i]\n",
        "        B[:, i - 1] = np.linalg.pinv(Ai) @ Vi\n",
        "        #if i % 1000 == 0: print('book ' + str(i))\n",
        "      nR = new_R(train, U, B)\n",
        "      new_RMSE = rmse(nR,train.rating)\n",
        "      dRMSE = (RMSE - new_RMSE) #np.abs\n",
        "      #dRMSE = min(dRMSEu, dRMSEb) #np.abs\n",
        "      RMSE = new_RMSE.copy()\n",
        "      #print('dRMSE = ' + str(dRMSE))\n",
        "      #print('RMSE = ' + str(RMSE))\n",
        "      print(\"step: \", iter)\n",
        "      rms.append(RMSE)\n",
        "      iter += 1\n",
        "    w = {}\n",
        "    w['rms'] = rms\n",
        "    w['U'] = U\n",
        "    w['B'] = B\n",
        "\n",
        "    return w"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bTCjNpivg8ZR"
      },
      "source": [
        " traint, traincv = train_test_split(train,\n",
        "                               stratify=train['newuser_id'], \n",
        "                               test_size=0.1875,\n",
        "                               random_state=42)\n",
        "traint = traint.reset_index(drop=True)\n",
        "traincv = traincv.reset_index(drop=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BMwKfYXtg37s"
      },
      "source": [
        "ks = []\n",
        "trains = []\n",
        "cvs = []\n",
        "ndgs = []\n",
        "\n",
        "for k in [3]:\n",
        "  for alphau in  [ 0.125]:\n",
        "    for betab in  [0.075, 0.1, 0.2, 1]:\n",
        "      print(\"running for... alphau = \", alphau, \" and betab = \", betab)\n",
        "      w = ALS(traint, k, alphau, betab)\n",
        "      CVpred = new_R(traincv, w['U'], w['B'])\n",
        "      RMSE_CV = np.sqrt(np.mean((CVpred - traincv.rating) ** 2))\n",
        "      ranked = traincv.filter(['rating'])\n",
        "      ranked['pred'] = CVpred\n",
        "      ndgcv = ndcg_k(ranked.sort_values(by=['pred'], ascending = False).rating, len(ranked.sort_values(by=['pred'], ascending = False).rating))\n",
        "      ndgs.append(ndgcv)\n",
        "      ks.append(betab)\n",
        "      trains.append(w['rms'][-1])\n",
        "      cvs.append(RMSE_CV)\n",
        "      print(\"RMSEtrain: \", w['rms'][-1])\n",
        "      print(\"RMSECV: \", RMSE_CV)\n",
        "      print(\"done for: k= \", k, \"alphau= \", alphau, \"betab= \", betab)\n",
        "      print(\"RMSEtrain: \", w['rms'][-1])\n",
        "      print(\"RMSECV: \", RMSE_CV)\n",
        "      print(\"NDG: \", ndgcv)\n",
        "      print (\"w rms: \", w['rms'])\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "va5fFTKtuWB3"
      },
      "source": [
        "print(ks)\n",
        "print(trains)\n",
        "print(cvs)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IgNiqHj_D5Q8"
      },
      "source": [
        "w = ALS(train,  3, 0.1, 0.1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M7kqXQPuEHIz"
      },
      "source": [
        "R = w['U'].dot(w['B'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j3SIf-LjugbM"
      },
      "source": [
        "rflat = np.matrix.flatten(R)\n",
        "testy = np.repeat(np.array(train.newuser_id.unique()), 8000)\n",
        "booky = np.tile(np.array(finalbooks.newbookid), 15000)\n",
        "booky\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b0s-s90znGF4"
      },
      "source": [
        "testy = np.sort(testy)\n",
        "testy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ax9WqFKmmvOw"
      },
      "source": [
        "predictions = pd.DataFrame(np.column_stack((testy, booky, rflat)), columns=('newuser_id','newbookid', 'pred'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t-VxuJdon5yj"
      },
      "source": [
        "predictions"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GGLUGLy0lrm3"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "predictions.to_csv( '../tmp/predictions.csv' , index = False )\n",
        "!cp /tmp/predictions.csv drive/My\\ Drive/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iPHeyna4bzZe"
      },
      "source": [
        "## DEFINING THE TAIL\n",
        "tailcomp = ratings.groupby(by= 'newbookid', as_index=False).agg({'rating':pd.Series.count}).sort_values(by = 'rating', ascending = False)\n",
        "tot = sum(tailcomp['rating'])\n",
        "tailcomp['popshare']= [x/tot for x in tailcomp['rating']]\n",
        "tailcomp['popshare']= tailcomp['popshare'].cumsum()\n",
        "tailcomp['category']= ['Head' if x<0.95 else \"Tail\" for x in tailcomp['popshare']]\n",
        "\n",
        "tail = tailcomp.loc[tailcomp.popshare >= 0.95]\n",
        "tail"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_IR8ERlNb7q4"
      },
      "source": [
        "mfrank = test.merge(predictions,on = ['newbookid', 'newuser_id'])\n",
        "mfrank = mfrank.sort_values(by=['newuser_id', 'pred'], ascending=False)\n",
        "mfrank.head(5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_v0Z5j0_cM03"
      },
      "source": [
        "#train['conc']=train['newuser_id'].map(str)+train['newbookid'].map(str)\n",
        "#pred['conc']=pred['newuser_id'].map(str)+pred['newbookid'].map(str)\n",
        "#predfin = pred[~pred.conc.isin(train.conc)]\n",
        "#predfin.describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LDGo181lccWs"
      },
      "source": [
        "mflist = []\n",
        "for i in range(15000):\n",
        "    a = mfrank.loc[mfrank.newuser_id == i+1]['rating'].tolist()\n",
        "    mflist.append(a)\n",
        "    if (i+1)%1000 == 0: print(\"done: \", i+1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jjPXV6WZckQV"
      },
      "source": [
        "b = np.array([ndcg_k(r, len(r)) for r in mflist])\n",
        "\n",
        "\n",
        "facet, axes = plt.subplots(1, 1, figsize=(10, 3))\n",
        "n, bins, patches = plt.hist(b, 200, facecolor='blue', alpha=0.5) #, log = True)   \n",
        "plt.title('Distribution of NDGC among Users for the MF model')\n",
        "plt.show()\n",
        "\n",
        "# [ndcg_k(r, len(r)) for r in poplista]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GhWpswzfnJ21"
      },
      "source": [
        "d = b[b == 1]\n",
        "sum(d)/15000"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cXwH4Fv6creF"
      },
      "source": [
        "top10 = predictions.sort_values('pred',ascending = False).groupby('newuser_id').head(10)\n",
        "top50 = predictions.sort_values('pred',ascending = False).groupby('newuser_id').head(50)\n",
        "\n",
        "print('(1) MF Model RMSE: ', np.round(rmse(mfrank['pred'],mfrank['rating']), decimals=3))\n",
        "print('(2) MF Model NDCG: ', np.round(mean_ndcg(mflist), decimals=3))\n",
        "print(\"(2) Median NDCG: \", np.round(np.median(b), decimals=3))\n",
        "print(\"(2) Share of NDCG =1 among Users: \", np.round(sum(d)/15000, decimals=3))\n",
        "print('(3) MF Model Div10 Score: ',np.round(sum(np.in1d(top10.newbookid, tail.newbookid))/len(top10), decimals=3))\n",
        "print('(3) MF Model Div50 Score: ',np.round(sum(np.in1d(top50.newbookid, tail.newbookid))/len(top50), decimals=3))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ku8v8N5ynYZk"
      },
      "source": [
        "mfranktrain = train.merge(predictions,on = ['newbookid', 'newuser_id'])\n",
        "mfranktrain = mfranktrain.sort_values(by=['newuser_id', 'pred'], ascending=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IMMmCEbYnbB-"
      },
      "source": [
        "mflisttrain = []\n",
        "for i in range(15000):\n",
        "    a = mfranktrain.loc[mfranktrain.newuser_id == i+1]['rating'].tolist()\n",
        "    mflisttrain.append(a)\n",
        "    if (i+1)%1000 == 0: print(\"done: \", i+1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h47iTsfOndkm"
      },
      "source": [
        "print('(1) MF Train Model RMSE: ', np.round(rmse(mfranktrain['pred'],mfranktrain['rating']), decimals=3))\n",
        "print('(2) MF Train Model NDCG: ', np.round(mean_ndcg(mflisttrain), decimals=3))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M7VRASwhpOA4"
      },
      "source": [
        "w['rms'][-1]"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}