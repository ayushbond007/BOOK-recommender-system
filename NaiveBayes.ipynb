{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NaiveBayes.ipynb",
      "provenance": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ayushbond007/BOOK-recommender-system/blob/main/NaiveBayes.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SaEMUd4nSBYJ"
      },
      "source": [
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import collections\n",
        "\n",
        "# visualization\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "# tools\n",
        "import scipy\n",
        "import math\n",
        "import random\n",
        "import sklearn\n",
        "import string\n",
        "from nltk.corpus import stopwords\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cWFgOC79mNuQ",
        "outputId": "0788cdc3-d055-4252-8fae-a221a479ef94"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5fzW-t-7mmA1"
      },
      "source": [
        "finalbooks= pd.read_csv(\"/content/drive/MyDrive/BOOK RECOMENDATION /finalfor modelling.csv\")\n",
        "rating= pd.read_csv(\"/content/drive/MyDrive/BOOK RECOMENDATION /new_rating.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Eid_fYsSSUJ"
      },
      "source": [
        "\n",
        "\n",
        "def dcg_k(r, k):\n",
        "    r = np.asfarray(r)[:k]\n",
        "    return np.sum(2**r / np.log2(np.arange(2, r.size + 2)))      \n",
        "\n",
        "\n",
        "\n",
        "def ndcg_k(r, k):\n",
        "\n",
        "    dcg_max = dcg_k(sorted(r, reverse=True), k)\n",
        "    if not dcg_max:\n",
        "        return 0.\n",
        "    return dcg_k(r, k) / dcg_max\n",
        "\n",
        "def mean_ndcg(rs):\n",
        "\n",
        "    return np.mean([ndcg_k(r, len(r)) for r in rs])\n",
        "\n",
        "def rmse(y,h):\n",
        "\n",
        "    a = y-h\n",
        "\n",
        "    return np.sqrt(sum(a**2)/len(a))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kJ0cPT69SZgM"
      },
      "source": [
        "## DEFINING THE TAIL\n",
        "tailcomp = ratings.groupby(by= 'newbookid', as_index=False).agg({'rating':pd.Series.count}).sort_values(by = 'rating', ascending = False)\n",
        "tot = sum(tailcomp['rating'])\n",
        "tailcomp['popshare']= [x/tot for x in tailcomp['rating']]\n",
        "tailcomp['popshare']= tailcomp['popshare'].cumsum()\n",
        "tailcomp['category']= ['Head' if x<0.95 else \"Tail\" for x in tailcomp['popshare']]\n",
        "\n",
        "tail = tailcomp.loc[tailcomp.popshare >= 0.95]\n",
        "tail"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tBEddNjdSkkD"
      },
      "source": [
        "def get_words(message):\n",
        "  \n",
        "\n",
        "    words = message\n",
        "    words = words.split(\" \")\n",
        "    words = [x.lower() for x in words]\n",
        "\n",
        "    return words\n",
        "\n",
        "\n",
        "\n",
        "def create_dictionary(messages):\n",
        "\n",
        "    word_counts = collections.defaultdict(int)\n",
        "\n",
        "    for message in messages:\n",
        "        for word in set(get_words(message)):\n",
        "            word_counts[word] += 1\n",
        "\n",
        "    resulting_dictionary = {}\n",
        "\n",
        "    for word, count in word_counts.items():\n",
        "        if count >= 25 and word not in stopwords.words('english') and len(word) > 1:\n",
        "            next_index = len(resulting_dictionary)\n",
        "            resulting_dictionary[word] = next_index\n",
        "\n",
        "    return resulting_dictionary\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def transform_text(messages, word_dictionary):\n",
        "\n",
        "    A = np.zeros((len(messages), len(word_dictionary)))\n",
        "\n",
        "    for i, message in enumerate(messages):\n",
        "        for word in get_words(message):\n",
        "            if word in word_dictionary:\n",
        "                A[i, word_dictionary[word]] += 1\n",
        "\n",
        "    return A\n",
        "\n",
        "\n",
        "\n",
        "def fit_naive_bayes_model(matrix, labels):\n",
        "\n",
        "\n",
        "\n",
        "    model = {}\n",
        "\n",
        "    phi = (1. * sum(labels) / len(labels))*0.95+0.05*0.5\n",
        "    model['logphi_0'] = np.log(1.-phi)\n",
        "    model['logphi_1'] = np.log(phi)\n",
        "    theta_0 = (matrix[labels == 0]).sum(axis=0) + 1\n",
        "    theta_1 = (matrix[labels == 1]).sum(axis=0) + 1\n",
        "    theta_0 /= theta_0.sum()\n",
        "    theta_1 /= theta_1.sum()\n",
        "    model['logtheta_0'] = np.log(theta_0)\n",
        "    model['logtheta_1'] = np.log(theta_1)\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "\n",
        "def predict_from_naive_bayes_model(model, matrix):\n",
        "\n",
        " \n",
        "    output = np.zeros(matrix.shape[0])\n",
        "\n",
        "    logphi_0 = model['logphi_0']\n",
        "    logphi_1 = model['logphi_1']\n",
        "    logtheta_0 = model['logtheta_0']\n",
        "    logtheta_1 = model['logtheta_1']\n",
        "    logprobs_0 = (matrix * logtheta_0).sum(axis=1) + logphi_0\n",
        "    logprobs_1 = (matrix * logtheta_1).sum(axis=1) + logphi_1\n",
        "\n",
        "    output = (logprobs_1/(logprobs_1+logprobs_0))\n",
        "    return output\n",
        "\n",
        "\n",
        "\n",
        "def get_top_five_naive_bayes_words(model, dictionary):\n",
        "\n",
        "    ids = np.argsort(model['logtheta_0'] - model['logtheta_1'])[:5]\n",
        "\n",
        "    reverse_dictionary = {i: word for word, i in dictionary.items()}\n",
        "\n",
        "    return [reverse_dictionary[i] for i in ids]\n",
        "  \n",
        " \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MtMtsa1S42wS"
      },
      "source": [
        "import collections\n",
        "finalbooks['snippet'] = finalbooks['snippet'].fillna(finalbooks['title'])\n",
        "finalbooks['snippet'] = finalbooks['snippet'].str.replace(r'[^\\w\\s]',\"\")\n",
        "finalbooks['snippet'] = finalbooks['snippet'].fillna(finalbooks['tag_cloud'])\n",
        "#finalbooks['tag_cloud'] = finalbooks['tag_cloud'].str.replace('-',\" \")\n",
        "#finalbooks['words'] = finalbooks['snippet'] +\" \"+finalbooks['tag_cloud']+\" \"+finalbooks['first_author']\n",
        "dico = create_dictionary(finalbooks['snippet'])\n",
        "dico"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gcMaGo_nSi4S"
      },
      "source": [
        "len(dico)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xGs3LWQH428r"
      },
      "source": [
        "A = transform_text(finalbooks['snippet'], dico)\n",
        "finalbooks['binary']= [1 if x >=4 else 0 for x in finalbooks['average_rating']]\n",
        "ratings['binary']= [1 if x >=4 else 0 for x in ratings['rating']]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TlfAnw-M43HW"
      },
      "source": [
        "allpreds = []\n",
        "topwords = []\n",
        "indicators = np.zeros(len(dico))\n",
        "for i in range(15000):\n",
        "    User = train.loc[train.newuser_id == i+1].sort_values('newbookid')\n",
        "    User['binary']= [1 if x >=4 else 0 for x in User['rating']]\n",
        "    A[User['newbookid']-1,:] \n",
        "    model = fit_naive_bayes_model(A[User['newbookid']-1,:], User['binary'])\n",
        "    result = predict_from_naive_bayes_model(model, A)\n",
        "    UserRes = finalbooks.filter(['newbookid'])\n",
        "    UserRes['newuser_id'] = i+1 \n",
        "    UserRes['pred'] = result\n",
        "    allpreds.append(UserRes)\n",
        "    #top5 = get_top_five_naive_bayes_words(model, dico)\n",
        "    #topwords.append(top5)\n",
        "    indicators = indicators + (model['logtheta_0'] - model['logtheta_1'])\n",
        "    if (i+1)%1000 == 0: print(\"done: \", i+1)\n",
        "## Append in a list and then use concat\n",
        "## get_top_five_naive_bayes_words(model, dico)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k7Y8vWwUjyaC"
      },
      "source": [
        "indicators = indicators*15000\n",
        "ids = np.argsort(-indicators)[:5]\n",
        "reverse_dictionary = {i: word for word, i in dico.items()}\n",
        "[reverse_dictionary[i] for i in ids]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L36xI_jylgyo"
      },
      "source": [
        "np.sort(indicators*1000000000000)[:5]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vncNq2Eq43Pw"
      },
      "source": [
        "fivewords = np.concatenate(topwords, axis=0 )\n",
        "from collections import Counter\n",
        "for key, value in sorted(Counter(fivewords).items(), reverse=True, key=lambda item: item[1]):\n",
        "    print(\"%s: %s\" % (key, value))\n",
        "\n",
        "\n",
        "#Bayes =pd.DataFrame(predictions, columns=['newbookid', 'newuser_id', 'pred']) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5CplV6-hqH_g"
      },
      "source": [
        "predictions = np.concatenate(allpreds, axis=0 )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wm5qHRTSqbg4"
      },
      "source": [
        "bayes =pd.DataFrame(predictions, columns=['newbookid','newuser_id', 'pred']) \n",
        "bayes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h1NjMmSCSk99"
      },
      "source": [
        "bayesrank = test.merge(bayes,on = ['newbookid', 'newuser_id'])\n",
        "bayesrank = bayesrank.sort_values(by=['newuser_id', 'pred'], ascending=False)\n",
        "bayesrank.head(5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v0GmnLQqSlBe"
      },
      "source": [
        "bayesrank['pred']=bayesrank['pred']*4+1\n",
        "bayesrank.head(5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LCOgdfDurI5O"
      },
      "source": [
        "bayesrank['pred'].min()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zm17ziRiSk7G"
      },
      "source": [
        "train['conc']=train['newuser_id'].map(str)+train['newbookid'].map(str)\n",
        "bayes['conc']=bayes['newuser_id'].map(str)+bayes['newbookid'].map(str)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6tF1HE3VEPjZ"
      },
      "source": [
        "bayesfin = bayes[~bayes.conc.isin(train.conc)]\n",
        "bayesfin.describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-lXwHFLcWvOS"
      },
      "source": [
        "bayeslist = []\n",
        "for i in range(15000):\n",
        "    a = bayesrank.loc[bayesrank.newuser_id == i+1]['rating'].tolist()\n",
        "    bayeslist.append(a)\n",
        "    if (i+1)%1000 == 0: print(\"done: \", i+1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "to3brz1NWq16"
      },
      "source": [
        "b = np.array([ndcg_k(r, len(r)) for r in bayeslist])\n",
        "\n",
        "facet, axes = plt.subplots(1, 1, figsize=(10, 3))\n",
        "n, bins, patches = plt.hist(b, 200, facecolor='blue', alpha=0.5) #, log = True)   \n",
        "plt.title('Distribution of NDGC among Users for the Bayes model')\n",
        "plt.show()\n",
        "\n",
        "# [ndcg_k(r, len(r)) for r in poplista]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R5PPCmZRm33H"
      },
      "source": [
        "d = b[b == 1]\n",
        "sum(d)/15000"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8c4dC10AWpbJ"
      },
      "source": [
        "#top10 = bayesfin.sort_values('pred',ascending = False).groupby('newuser_id').head(10)\n",
        "#top50 = bayesfin.sort_values('pred',ascending = False).groupby('newuser_id').head(50)\n",
        "\n",
        "print('(1) Bayes Model RMSE: ', np.round(rmse(bayesrank['pred'],bayesrank['rating']), decimals=3))\n",
        "print('(2) Bayes Model NDCG: ', np.round(mean_ndcg(bayeslist), decimals=3))\n",
        "print(\"(2) Median NDCG: \", np.round(np.median(b), decimals=3))\n",
        "print(\"(2) Share of NDCG =1 among Users: \", np.round(sum(d)/15000, decimals=3))\n",
        "#print('(3) Bayes Model Div10 Score: ',np.round(sum(np.in1d(top10.newbookid, tail.newbookid))/len(top10), decimals=3))\n",
        "#print('(3) Bayes Model Div50 Score: ',np.round(sum(np.in1d(top50.newbookid, tail.newbookid))/len(top50), decimals=3))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jee7hVycrtFC"
      },
      "source": [
        "bayesranktrain = train.merge(bayes,on = ['newbookid', 'newuser_id'])\n",
        "bayesranktrain = bayesranktrain.sort_values(by=['newuser_id', 'pred'], ascending=False)\n",
        "bayesranktrain['pred']=bayesranktrain['pred']*4+1\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cJeV3QEIr2Bf"
      },
      "source": [
        "bayeslisttrain = []\n",
        "for i in range(15000):\n",
        "    a = bayesranktrain.loc[bayesranktrain.newuser_id == i+1]['rating'].tolist()\n",
        "    bayeslisttrain.append(a)\n",
        "    if (i+1)%1000 == 0: print(\"done: \", i+1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TVKiH5N6Sk4C"
      },
      "source": [
        "\n",
        "\n",
        "# print('Popularity Model MAP: ', mean_average_precision(poplistb))\n",
        "print('(1) Bayes Model Train RMSE: ', np.round(rmse(bayesranktrain['pred'],bayesranktrain['rating']), decimals=3))\n",
        "print('(2) Bayes Model Train NDCG: ', np.round(mean_ndcg(bayeslisttrain), decimals=3))\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}